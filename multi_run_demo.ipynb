{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8630285,"sourceType":"datasetVersion","datasetId":5167383}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom collections import Counter\nimport os\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets, models\nimport torchvision.transforms.functional as TF\nimport torchvision.models as models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-08T14:20:23.339534Z","iopub.status.idle":"2024-06-08T14:20:28.690378Z","shell.execute_reply.started":"2024-06-08T14:20:23.340190Z","shell.execute_reply":"2024-06-08T14:20:28.689538Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n# Define transformations for the training and testing sets\ntransform = transforms.Compose([\n    transforms.ToTensor()\n])\n\ndef load_images_from_folder(data_dir, num_channels, width, height, labels):\n  \"\"\"Loads images from a folder with 5 multichannel inputs.\n\n  Args:\n    data_dir: Path to the data directory.\n    num_channels: Number of channels for each image (1 for grayscale, 3 for RGB).\n    width: Target width for resizing images.\n    height: Target height for resizing images.\n    labels: List of class labels.\n\n  Returns:\n    X: A numpy array of shape (num_images, num_channels * 5, height, width).\n    y: A numpy array of shape (num_images,) containing class labels.\n  \"\"\"\n\n  X = []\n  y = []\n  extension = [\".png\", \".jpg\", \".jpeg\"]\n  for label_index, label_dir in enumerate(sorted(os.listdir(data_dir))):\n    if not label_dir.startswith(\".\"):\n      label_path = os.path.join(data_dir, label_dir)\n      i = 0\n      channel_data = []  # List to store data for all 5 channels\n\n      for fname in sorted(os.listdir(label_path)):\n        if any(fname.endswith(ext) for ext in extension) and not fname.startswith(\".\"):\n          i += 1\n          path = os.path.join(label_path, fname)\n          img = cv2.imread(path, cv2.IMREAD_COLOR if num_channels == 3 else cv2.IMREAD_GRAYSCALE)\n          img = cv2.resize(img, (width, height))\n          channel_data.append(img)\n\n          # Check if all 5 channels are loaded, then process and append\n          if i % 5 == 0:\n            if num_channels == 1:\n              feature = np.stack(channel_data, axis=-1)\n            elif num_channels == 3:\n              feature = np.concatenate(channel_data, axis=-1)\n            # Reshape to (num_channels * 5, height, width) before appending to X\n            feature = np.transpose(feature, (2, 0, 1))\n            X.append(feature)\n            y.append(label_index)\n            channel_data = []  # Reset channel data list\n\n  return np.asarray(X), np.asarray(y)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:20:28.692108Z","iopub.execute_input":"2024-06-08T14:20:28.694020Z","iopub.status.idle":"2024-06-08T14:20:28.881878Z","shell.execute_reply.started":"2024-06-08T14:20:28.693989Z","shell.execute_reply":"2024-06-08T14:20:28.881052Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"A2_1train_dir =\"/kaggle/input/vibeid-a1/A1/train\"\nA2_1test_dir = \"/kaggle/input/vibeid-a1/A1/test\"","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:20:28.883022Z","iopub.execute_input":"2024-06-08T14:20:28.883371Z","iopub.status.idle":"2024-06-08T14:20:28.887650Z","shell.execute_reply.started":"2024-06-08T14:20:28.883341Z","shell.execute_reply":"2024-06-08T14:20:28.886719Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"num_channels = 3\nwidth = 128\nheight =128\nnum_classes = 100\nlabels = sorted(os.listdir(A2_1train_dir))[:num_classes]  # Assuming labels are sorted alphabetically\nprint(labels)\nX_train, y_train = load_images_from_folder(A2_1train_dir, num_channels, width, height, labels)\nX_test, y_test = load_images_from_folder(A2_1test_dir, num_channels, width, height, labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:20:28.889669Z","iopub.execute_input":"2024-06-08T14:20:28.890062Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Assuming X_train, y_train, X_test, and y_test are numpy arrays or PyTorch tensors\n\n# Convert train and test data into PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Assuming y_train is categorical\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.long)  # Assuming y_test is categorical\nnum_epochs = 10\nbatch_size = 16\n# Create DataLoaders with rearranged data\ntrain_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train data shape (X_train):\", X_train_tensor.shape)\nprint(\"Train data labels shape (y_train):\", y_train_tensor.shape)\n\nprint(\"Test data shape (X_test):\", X_test_tensor.shape)\nprint(\"Test data labels shape (y_test):\", y_test_tensor.shape)\nimport torch\nfrom collections import Counter\n\n# Assuming y_train_tensor and y_test_tensor are already defined as tensors of labels\n\n# Count the number of samples per class in the training set\ntrain_class_counts = Counter(y_train_tensor.numpy())\nprint(\"Training set class distribution:\")\nfor class_label, count in train_class_counts.items():\n    print(f\"Class {class_label}: {count} samples\")\n\n# Count the number of samples per class in the test set\ntest_class_counts = Counter(y_test_tensor.numpy())\nprint(\"\\nTest set class distribution:\")\nfor class_label, count in test_class_counts.items():\n    print(f\"Class {class_label}: {count} samples\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets, models\nimport torchvision.transforms.functional as TF\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\n\nclass CustomResNet(nn.Module):\n    def __init__(self):\n        super(CustomResNet, self).__init__()\n        resnet =  models.resnet50(pretrained=False)\n        for param in resnet.parameters():\n          param.requires_grad = True\n        resnet.conv1 =  nn.Conv2d(15, 64, kernel_size=7, stride=2, padding=3)\n        num_ftrs = resnet.fc.in_features\n        resnet.fc = nn.Sequential(nn.Linear(num_ftrs,100))\n        self.resnet = resnet\n    def forward(self, x):\n        return self.resnet(x)\ncustom_resnet = CustomResNet()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(custom_resnet.parameters())\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.01, patience=3, verbose=True)\noptimizer =  optim.Adam(custom_resnet.parameters())\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncustom_resnet.to(device)\nfrom torch.optim import lr_scheduler\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\nnum_epochs = 100\ndef train_and_test_model(model, train_loader, test_loader, criterion, optimizer, scheduler, device, num_epochs):\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()  # Set the model to training mode\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        epoch_loss = running_loss / len(train_loader)\n        epoch_acc = correct / total\n\n#         print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.4f}\")\n\n        # Testing phase\n        model.eval()  # Set the model to evaluation mode\n        test_correct = 0\n        test_total = 0\n        test_loss = 0.0\n\n        with torch.no_grad():  # Enable gradient computation during inference\n            for images, labels in test_loader:\n                images, labels = images.to(device), labels.to(device)\n\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                test_loss += loss.item()\n\n                _, predicted = torch.max(outputs, 1)\n                test_total += labels.size(0)\n                test_correct += (predicted == labels).sum().item()\n\n        test_loss /= len(test_loader)\n        test_accuracy = test_correct / test_total\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n\n        # Update learning rate scheduler\n        if scheduler is not None:\n            scheduler.step(test_loss)\n\n    print(\"Training completed!\")\n# Train and test the model\ntrain_and_test_model(custom_resnet, train_loader, test_loader, criterion, optimizer, scheduler, device, num_epochs)\nprint(\"Training completed!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}